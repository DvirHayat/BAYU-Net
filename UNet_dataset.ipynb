{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "z-1W_AsCgbdR"
      ],
      "mount_file_id": "11gZy4a_tm_uU_AEKGdcJ-I0RmnbIYhsG",
      "authorship_tag": "ABX9TyNUPG2VQOJ2nKkccjmn8Qwd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DvirHayat/BAYU-Net/blob/main/UNet_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the ultralytics package\n",
        "!pip install ultralytics\n",
        "\n",
        "# Install the roboflow package\n",
        "!pip install roboflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGKiLOJ0csAG",
        "outputId": "5f2c0b08-5676-44c4-daac-6f1053af70db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.150-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.150-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.150 ultralytics-thop-2.0.14\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.65-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.58.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n",
            "Downloading roboflow-1.1.65-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow\n",
        "from google.colab import files, drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "afiY8UzncvSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f39acda-d7e0-4b15-b515-c4e49ae596ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "BASE_DATASET_DIR = \"/content/drive/MyDrive/dataset_for_Unet/1.0.1\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/dataset_for_Unet/1.0.0/yolo_weights.pt\"            #Yolo model weights\n",
        "FULL_IMAGE_DIR_PATH = \"/content/drive/MyDrive/dataset_for_Unet/1.0.1/yolo_endpoint\"     #From where take the whole images\n",
        "YOLO_RESULT_OUTPUT_PATH = \"/content/drive/MyDrive/dataset_for_Unet/1.0.1/yolo_result\"   #yolo output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH1a_lo0c2Nf",
        "outputId": "d959dc41-4656-4b0a-cfef-2085b98ddc2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk3w049b3U1K"
      },
      "outputs": [],
      "source": [
        "# Load the YOLO model\n",
        "yolo_model = YOLO(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each one of the bounding box detected by the yolo need to be processed for the data set.\n",
        "\n",
        "We need to define the follwoing:\n",
        "* Fixed size"
      ],
      "metadata": {
        "id": "9yXB80J3fwqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FIXED_SIZE = (162,112)"
      ],
      "metadata": {
        "id": "XXOM4io6fv7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Process function"
      ],
      "metadata": {
        "id": "z-1W_AsCgbdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_image(orig_img, x1, y1, x2, y2):\n",
        "    try:\n",
        "        if orig_img is None:\n",
        "            raise ValueError(\"Input image is None\")\n",
        "\n",
        "        height, width = orig_img.shape[:2]\n",
        "\n",
        "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "\n",
        "        if x1 < 0 or y1 < 0 or x2 > width or y2 > height:\n",
        "            raise ValueError(f\"Crop coordinates out of bounds: ({x1}, {y1}, {x2}, {y2}) for image size ({width}, {height})\")\n",
        "\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            raise ValueError(f\"Invalid crop box: x2 <= x1 or y2 <= y1\")\n",
        "\n",
        "        # Perform crop\n",
        "        cropped = orig_img[y1:y2, x1:x2]\n",
        "        return cropped\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] crop_image failed: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "VS4IA4lTgiJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def center_and_padd_image(image, target_width, target_height):\n",
        "    try:\n",
        "        if image is None:\n",
        "            raise ValueError(\"Input image is None\")\n",
        "\n",
        "        if not isinstance(image, np.ndarray):\n",
        "            raise TypeError(\"Input image must be a NumPy array\")\n",
        "\n",
        "        if len(image.shape) != 3:\n",
        "            raise ValueError(\"Input must be a color image with 3 channels\")\n",
        "\n",
        "        img_height, img_width = image.shape[:2]\n",
        "\n",
        "        if target_width < img_width or target_height < img_height:\n",
        "                raise ValueError(\n",
        "                              f\"Target size too small for padding: \"\n",
        "                              f\"image size = ({img_width}, {img_height}), \"\n",
        "                              f\"target size = ({target_width}, {target_height})\"\n",
        "                          )\n",
        "\n",
        "        # Calculate padding on each side\n",
        "        x_pad = target_width - img_width\n",
        "        y_pad = target_height - img_height\n",
        "\n",
        "        left = x_pad // 2\n",
        "        right = x_pad - left\n",
        "        top = y_pad // 2\n",
        "        bottom = y_pad - top\n",
        "\n",
        "        padded_image = cv2.copyMakeBorder(\n",
        "            image,\n",
        "            top=top,\n",
        "            bottom=bottom,\n",
        "            left=left,\n",
        "            right=right,\n",
        "            borderType=cv2.BORDER_CONSTANT,\n",
        "            value=[0, 0, 0]  # black padding\n",
        "        )\n",
        "\n",
        "        return padded_image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] center_and_padd_image failed: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "QA_lCg3Xgz0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Raw Dataset Creation"
      ],
      "metadata": {
        "id": "ZBCfE4aig2Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all png files in the directory\n",
        "image_name_list = [f for f in os.listdir(FULL_IMAGE_DIR_PATH) if f.lower().endswith('.png') and os.path.isfile(os.path.join(FULL_IMAGE_DIR_PATH, f))]\n",
        "\n",
        "# Get full paths\n",
        "full_image_paths = [os.path.join(FULL_IMAGE_DIR_PATH, image_name) for image_name in image_name_list]\n",
        "\n",
        "# Print filenames\n",
        "for path in full_image_paths:\n",
        "    print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHtvNPY5g1V0",
        "outputId": "a88a140b-504e-4b94-e3ca-f17136a95782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataset_for_Unet/1.0.1/yolo_endpoint/8_6.png\n",
            "/content/drive/MyDrive/dataset_for_Unet/1.0.1/yolo_endpoint/7_5.png\n",
            "/content/drive/MyDrive/dataset_for_Unet/1.0.1/yolo_endpoint/10_7.png\n",
            "/content/drive/MyDrive/dataset_for_Unet/1.0.1/yolo_endpoint/9_5.png\n",
            "/content/drive/MyDrive/dataset_for_Unet/1.0.1/yolo_endpoint/9_4.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " results = yolo_model(full_image_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QP9R7RzkrEj",
        "outputId": "460d0f9d-7e16-4149-8621-891cd7483b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 5 vertebreas, 261.5ms\n",
            "1: 640x640 9 vertebreas, 261.5ms\n",
            "2: 640x640 10 vertebreas, 261.5ms\n",
            "3: 640x640 9 vertebreas, 261.5ms\n",
            "4: 640x640 6 vertebreas, 261.5ms\n",
            "Speed: 8.3ms preprocess, 261.5ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_store(prediction, output_name, fixed_size=FIXED_SIZE, output_path=YOLO_RESULT_OUTPUT_PATH):\n",
        "    boxes = prediction.boxes\n",
        "    original_image = prediction.orig_img\n",
        "\n",
        "    for i, xyxy in enumerate(boxes.xyxy):\n",
        "        try:\n",
        "            x1, y1, x2, y2 = map(int, xyxy)\n",
        "\n",
        "            # Crop\n",
        "            cropped = crop_image(original_image, x1, y1, x2, y2)\n",
        "            if cropped is None:\n",
        "                print(f\"[WARNING] Skipping box {i}: crop failed\")\n",
        "                continue\n",
        "\n",
        "            # Center and pad to fixed size\n",
        "            padded = center_and_padd_image(cropped, fixed_size[0], fixed_size[1])\n",
        "            if padded is None:\n",
        "                print(f\"[WARNING] Skipping box {i}: padding failed\")\n",
        "                continue\n",
        "\n",
        "            # Construct unique filename per box\n",
        "            base_name = os.path.splitext(output_name)[0]\n",
        "            filename = f\"{base_name}_{i}.png\"\n",
        "            full_path = os.path.join(output_path, filename)\n",
        "\n",
        "            # Save the image\n",
        "            success = cv2.imwrite(full_path, padded)\n",
        "            if success:\n",
        "                print(f\"[INFO] Successfully processed box {i}\")\n",
        "            else:\n",
        "                print(f\"[ERROR] Failed to write image for box {i}: {full_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Failed on box {i}: {e}\")"
      ],
      "metadata": {
        "id": "D5eZQGLslpxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, result in enumerate(results):\n",
        "    output_name = f\"result_{idx}\"\n",
        "\n",
        "    try:\n",
        "        process_and_store(result, output_name=output_name)\n",
        "        print(f\"[INFO] Successfully processed result {idx}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Exception during processing of result {idx}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmqDx3QNno2j",
        "outputId": "5f39f40a-0153-4f84-eb18-07f53b075124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ERROR] Failed on box 0: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 1: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 2: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 3: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 4: name 'crop_image' is not defined\n",
            "[INFO] Successfully processed result 0\n",
            "[ERROR] Failed on box 0: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 1: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 2: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 3: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 4: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 5: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 6: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 7: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 8: name 'crop_image' is not defined\n",
            "[INFO] Successfully processed result 1\n",
            "[ERROR] Failed on box 0: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 1: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 2: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 3: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 4: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 5: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 6: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 7: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 8: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 9: name 'crop_image' is not defined\n",
            "[INFO] Successfully processed result 2\n",
            "[ERROR] Failed on box 0: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 1: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 2: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 3: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 4: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 5: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 6: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 7: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 8: name 'crop_image' is not defined\n",
            "[INFO] Successfully processed result 3\n",
            "[ERROR] Failed on box 0: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 1: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 2: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 3: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 4: name 'crop_image' is not defined\n",
            "[ERROR] Failed on box 5: name 'crop_image' is not defined\n",
            "[INFO] Successfully processed result 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you need to load the yolo result to roboflow extract the dataset as coco-segmentation and process them into output."
      ],
      "metadata": {
        "id": "QUCrTMn7FA0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preperation\n",
        "After the dataset is annonated in roboflow we want to load it and get it ready for the unet to use/ train"
      ],
      "metadata": {
        "id": "MypV6MXMSt9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the roboflow dataset it can be chnaged from dataset to another\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"nQsUcNQlcVFxKyvIhf5W\")\n",
        "project = rf.workspace(\"unet-vertebrae-segmentation\").project(\"my-first-project-5xsoq\")\n",
        "version = project.version(5)\n",
        "dataset = version.download(\"coco-segmentation\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFP2zzZMS88O",
        "outputId": "adb49c4a-b677-49d8-811a-f319daea328e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in My-First-Project-5 to coco-segmentation:: 100%|██████████| 311/311 [00:00<00:00, 2961.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to My-First-Project-5 in coco-segmentation:: 100%|██████████| 156/156 [00:00<00:00, 6969.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Move the dataset into drive\n",
        "shutil.move(\"/content/My-First-Project-5\", BASE_DATASET_DIR)\n",
        "\n"
      ],
      "metadata": {
        "id": "eFSqXT3Vzwnw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a24add59-83e9-4e22-97b2-bbd573fd6c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/dataset_for_Unet/1.0.1/My-First-Project-5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the path of the new data set from roboflow\n",
        "robo_dataset_dir = os.path.join(BASE_DATASET_DIR, \"My-First-Project-5\")"
      ],
      "metadata": {
        "id": "W-_XswIE5rv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The dataset is in coco-segmentation format to get the model trained we need to convert the dataset into png mask format."
      ],
      "metadata": {
        "id": "IeVa5LamT8Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycocotools opencv-python pillow"
      ],
      "metadata": {
        "id": "bhUYx14uTZpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719454dc-469b-446f-b487-95e7e65338c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "def coco_to_mask(ann_path, mask_output_dir, class_id=None):\n",
        "    \"\"\"\n",
        "    Converts COCO segmentation annotations into binary mask PNGs.\n",
        "\n",
        "    Parameters:\n",
        "    ann_path (str): Path to the COCO JSON annotation file.\n",
        "    mask_output_dir (str): Directory where the output binary mask images will be saved.\n",
        "    class_id (int, optional): If specified, only annotations with this category ID will be used for the masks.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(mask_output_dir, exist_ok=True)\n",
        "\n",
        "    # Load the COCO annotations\n",
        "    coco = COCO(ann_path)\n",
        "\n",
        "    # Get all image IDs in the dataset\n",
        "    image_ids = coco.getImgIds()\n",
        "\n",
        "    for img_id in tqdm(image_ids):\n",
        "        # Load metadata for the current image\n",
        "        img_info = coco.loadImgs(img_id)[0]\n",
        "        height, width = img_info[\"height\"], img_info[\"width\"]\n",
        "        img_name = img_info[\"file_name\"]\n",
        "\n",
        "        # Create an empty mask the size of the image\n",
        "        mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "        # Get annotation IDs for this image\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "\n",
        "        # Load all annotations\n",
        "        anns = coco.loadAnns(ann_ids)\n",
        "\n",
        "        for ann in anns:\n",
        "            # Skip annotations that don't match the specified class (if provided)\n",
        "            if class_id and ann['category_id'] != class_id:\n",
        "                continue\n",
        "\n",
        "            # Merge the annotation mask with the main mask\n",
        "            mask = np.maximum(mask, coco.annToMask(ann))\n",
        "\n",
        "        # Save the binary mask as a grayscale PNG image (0 for background, 255 for object)\n",
        "        mask_path = os.path.join(mask_output_dir, img_name.replace('.jpg', '.png'))\n",
        "        Image.fromarray(mask * 255).convert(\"L\").save(mask_path)\n"
      ],
      "metadata": {
        "id": "fsHsFPEOT_G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_MASK_DIR = os.path.join(robo_dataset_dir, \"mask\")"
      ],
      "metadata": {
        "id": "z2pCygZiUpIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "for split in splits:\n",
        "    img_dir = os.path.join(robo_dataset_dir, split)\n",
        "    ann_path = os.path.join(img_dir, \"_annotations.coco.json\")  # <-- per folder\n",
        "    mask_output_dir = os.path.join(BASE_MASK_DIR, split)\n",
        "\n",
        "    print(f\"Processing {split} set...\")\n",
        "    coco_to_mask(\n",
        "        ann_path=ann_path,\n",
        "        mask_output_dir=mask_output_dir\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHk3SEfCUKdc",
        "outputId": "1bf872d7-aebf-40fd-8dd0-360f3862290f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing train set...\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 116/116 [00:01<00:00, 87.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing valid set...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 93.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing test set...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 84.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this moment the data is ready to be used in training."
      ],
      "metadata": {
        "id": "B2MLnRtrEpej"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xm3AzlYaFgln"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}